{"cells": [{"cell_type": "code", "metadata": {}, "source": ["from transformers import EncoderDecoderModel, BertTokenizerFast, Trainer, TrainingArguments\n", "from datasets import Dataset\n", "import pandas as pd"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["data = {\n", "    \"input_text\": [\n", "        \"What are the key challenges in scaling biotech startups in North Carolina?\",\n", "        \"Describe a successful commercialization of research in the NC Research Triangle.\"\n", "    ],\n", "    \"target_text\": [\n", "        \"Biotech startups in NC face regulatory, funding, and talent acquisition challenges.\",\n", "        \"A Duke lab developed a novel diagnostic tool, licensed it to a local company, and scaled production via a university-industry partnership.\"\n", "    ]\n", "}\n", "\n", "df = pd.DataFrame(data)\n", "dataset = Dataset.from_pandas(df)"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n", "\n", "def preprocess_function(examples):\n", "    inputs = tokenizer(examples[\"input_text\"], padding=\"max_length\", truncation=True, max_length=128)\n", "    targets = tokenizer(examples[\"target_text\"], padding=\"max_length\", truncation=True, max_length=128)\n", "    inputs[\"labels\"] = targets[\"input_ids\"]\n", "    return inputs\n", "\n", "tokenized_dataset = dataset.map(preprocess_function, batched=True)"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-uncased\", \"bert-base-uncased\")"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["training_args = TrainingArguments(\n", "    output_dir=\"./llm_advisory_output\",\n", "    evaluation_strategy=\"epoch\",\n", "    learning_rate=2e-5,\n", "    per_device_train_batch_size=2,\n", "    num_train_epochs=5,\n", "    weight_decay=0.01,\n", "    save_total_limit=1,\n", "    logging_dir=\"./logs\"\n", ")"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["trainer = Trainer(\n", "    model=model,\n", "    args=training_args,\n", "    train_dataset=tokenized_dataset,\n", "    eval_dataset=tokenized_dataset,\n", "    tokenizer=tokenizer\n", ")\n", "\n", "trainer.train()"], "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 2}